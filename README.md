# ğŸŒ¾ Projet_1: Classification de routes et champs par CNN

## Description
Ce projet explore la classification d'images en deux catÃ©gories : **routes** et **champs**, en comparant trois types de reprÃ©sentations :
- Images en **RGB** (couleur originale)
- Images en **niveaux de gris (L)**
- Images en **niveaux de gris avec Ã©galisation locale d'histogramme (L-LHE)**

L'objectif est de dÃ©terminer si la couleur est nÃ©cessaire ou si des prÃ©-traitements des images amÃ©liorent la performance d'un rÃ©seau de neurones convolutionnel (CNN).

---

## Jeu de donnÃ©es
- Nombre total dâ€™images : **90**
- CatÃ©gories : `route`, `champ`
- Taille des images : 150 Ã— 150 pixels

| Type de donnÃ©es | Description |
|-----------------|------------|
| RGB             | Image couleur originale |
| L               | Conversion en niveaux de gris |
| L-LHE           | Niveaux de gris + Ã©galisation locale dâ€™histogramme |

---

## Architecture du modÃ¨le CNN
- 2 blocs convolution + max pooling
- 1 couche `Flatten`
- 1 couche dense (128 neurones, ReLU)
- 1 couche de sortie (sigmoÃ¯de pour classification binaire)
- Dropout = 0.5 pour rÃ©gularisation
- Optimiseur : `Adam`
- Fonction de perte : `binary_crossentropy`

---

## RÃ©sultats

| Jeu de donnÃ©es | PrÃ©cision entraÃ®nement | PrÃ©cision validation |
|----------------|------------------------|---------------------|
| RGB            | ~87,5 %               | ~66,7 %             |
| L (gris)       | ~90 %                 | ~83,3 %             |
| L-LHE          | ~75 % (instable)      | ~50â€“55 %            |

### InterprÃ©tation
- âœ… **Niveaux de gris (L)** : meilleur compromis entre apprentissage et gÃ©nÃ©ralisation.
- âš ï¸ **RGB** : surapprentissage possible.
- âŒ **L-LHE** : Ã©galisation locale trop perturbante pour le CNN.

---

## AmÃ©liorations possibles
- Augmentation de donnÃ©es (rotations, flips, variations de luminositÃ©)
- RÃ©gularisation des couches convolutionnelles (`kernel_regularizer=L2`)
- Ajustement de la taille du batch (8 ou 16)
- Early stopping pour Ã©viter le surapprentissage
- Validation croisÃ©e k-fold pour plus de robustesse
- Apprentissage par transfert avec modÃ¨les prÃ©-entraÃ®nÃ©s (VGG16, MobileNetV2, ResNet)

---

## Conclusion
- La **couleur nâ€™est pas indispensable** pour ce jeu de donnÃ©es.
- Lâ€™**Ã©galisation locale** nâ€™amÃ©liore pas la performance et peut la dÃ©grader.
- Avec un petit dataset, lâ€™**augmentation de donnÃ©es** et/ou **lâ€™apprentissage par transfert** est fortement recommandÃ©.

---

## Exemple dâ€™utilisation (Python/Keras)
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])


**-----------------------------------------------------------------------------------------------------------------------------------------------------**


# ğŸš€ Projet_2: Extraction de DÃ©finitions
 
## ğŸ¯ Objectif
DÃ©velopper un modÃ¨le capable de classifier automatiquement des dÃ©finitions extraites de textes en **bonnes** ou **mauvaises dÃ©finitions**, Ã  lâ€™aide de **rÃ©seaux de neurones** (MLP, CNN, LSTM).

## ğŸ“Œ Sommaire des tÃ¢ches
1. **Extraction et PrÃ©traitement des donnÃ©es**
   - TÃ©lÃ©chargement des dÃ©finitions (fichiers `wiki_good.txt` et `wiki_bad.txt`).  
   - Construction dâ€™un DataFrame avec deux colonnes :  
     - `CONTENT` : phrases  
     - `CLASS` : Ã©tiquette (`1` = bonne dÃ©finition, `0` = mauvaise dÃ©finition).  
   - Nettoyage des textes :  
     - Suppression de parenthÃ¨ses, chiffres, ponctuations.  
     - Tokenisation, mise en minuscules.  
     - Suppression des stopwords (sauf termes frÃ©quents utiles comme *is, type, an*).  
     - Lemmatisation.  

2. **Construction des jeux de donnÃ©es**
   - SÃ©paration : 80% **train**, 20% **test**.  
   - Tokenisation avec les 5000 mots les plus frÃ©quents.  
   - SÃ©quences normalisÃ©es avec `pad_sequences` (longueur 50).  
   - IntÃ©gration dâ€™un **embedding prÃ©-entraÃ®nÃ© (GloVe, 50d)**.

3. **ModÃ¨les de classification testÃ©s**
   - **RÃ©seau de neurones simple (MLP)**  
     - Accuracy test : ~83%  
     - PrÃ©sence dâ€™overfitting (Ã©cart moyen train/val â‰ˆ 0.08).  

   - **CNN (1D convolution)**  
     - Accuracy test : ~87%  
     - Performance meilleure mais overfitting plus marquÃ© (Ã©cart â‰ˆ 0.10).  

   - **LSTM (128 unitÃ©s)**  
     - Accuracy test : ~89%  
     - Meilleur modÃ¨le avec Ã©cart moyen plus faible (~0.06).  
     - Plus adaptÃ© pour traiter les sÃ©quences textuelles.  

4. **Optimisation des hyperparamÃ¨tres (LSTM)**
   - Recherche du meilleur **batch_size** et nombre de neurones.  
   - Meilleure configuration trouvÃ©e : **(128 neurones, batch_size = 200)**.  
   - Accuracy sur test set : **â‰ˆ 90%**.  

5. **PrÃ©diction sur une instance**
   - Test sur un exemple rÃ©el â†’ prÃ©diction correcte avec sortie sigmoid > 0.5.  

## ğŸ“Š RÃ©sultats
- Le **LSTM** est le plus performant pour la tÃ¢che dâ€™extraction de dÃ©finitions.  
- Bonne gÃ©nÃ©ralisation avec ~90% dâ€™accuracy sur lâ€™ensemble test.  

## ğŸ› ï¸ Technologies utilisÃ©es
- **Python**  
- **NLTK, Pandas, Numpy, Scikit-learn**  
- **Keras (Tensorflow backend)**  
- **Matplotlib, Seaborn**  
- **GloVe embeddings**

## âœ… Conclusion
Le projet dÃ©montre que les rÃ©seaux de neurones rÃ©currents (**LSTM**) surpassent les modÃ¨les simples (MLP) et convolutionnels (CNN) pour la tÃ¢che de classification de dÃ©finitions, grÃ¢ce Ã  leur capacitÃ© Ã  capturer les dÃ©pendances sÃ©quentielles du langage.  
