# ğŸš€ Projet_2: Extraction de DÃ©finitions
 
## ğŸ¯ Objectif
DÃ©velopper un modÃ¨le capable de classifier automatiquement des dÃ©finitions extraites de textes en **bonnes** ou **mauvaises dÃ©finitions**, Ã  lâ€™aide de **rÃ©seaux de neurones** (MLP, CNN, LSTM).

## ğŸ“Œ Sommaire des tÃ¢ches
1. **Extraction et PrÃ©traitement des donnÃ©es**
   - TÃ©lÃ©chargement des dÃ©finitions (fichiers `wiki_good.txt` et `wiki_bad.txt`).  
   - Construction dâ€™un DataFrame avec deux colonnes :  
     - `CONTENT` : phrases  
     - `CLASS` : Ã©tiquette (`1` = bonne dÃ©finition, `0` = mauvaise dÃ©finition).  
   - Nettoyage des textes :  
     - Suppression de parenthÃ¨ses, chiffres, ponctuations.  
     - Tokenisation, mise en minuscules.  
     - Suppression des stopwords (sauf termes frÃ©quents utiles comme *is, type, an*).  
     - Lemmatisation.  

2. **Construction des jeux de donnÃ©es**
   - SÃ©paration : 80% **train**, 20% **test**.  
   - Tokenisation avec les 5000 mots les plus frÃ©quents.  
   - SÃ©quences normalisÃ©es avec `pad_sequences` (longueur 50).  
   - IntÃ©gration dâ€™un **embedding prÃ©-entraÃ®nÃ© (GloVe, 50d)**.

3. **ModÃ¨les de classification testÃ©s**
   - **RÃ©seau de neurones simple (MLP)**  
     - Accuracy test : ~83%  
     - PrÃ©sence dâ€™overfitting (Ã©cart moyen train/val â‰ˆ 0.08).  

   - **CNN (1D convolution)**  
     - Accuracy test : ~87%  
     - Performance meilleure mais overfitting plus marquÃ© (Ã©cart â‰ˆ 0.10).  

   - **LSTM (128 unitÃ©s)**  
     - Accuracy test : ~89%  
     - Meilleur modÃ¨le avec Ã©cart moyen plus faible (~0.06).  
     - Plus adaptÃ© pour traiter les sÃ©quences textuelles.  

4. **Optimisation des hyperparamÃ¨tres (LSTM)**
   - Recherche du meilleur **batch_size** et nombre de neurones.  
   - Meilleure configuration trouvÃ©e : **(128 neurones, batch_size = 200)**.  
   - Accuracy sur test set : **â‰ˆ 90%**.  

5. **PrÃ©diction sur une instance**
   - Test sur un exemple rÃ©el â†’ prÃ©diction correcte avec sortie sigmoid > 0.5.  

## ğŸ“Š RÃ©sultats
- Le **LSTM** est le plus performant pour la tÃ¢che dâ€™extraction de dÃ©finitions.  
- Bonne gÃ©nÃ©ralisation avec ~90% dâ€™accuracy sur lâ€™ensemble test.  

## ğŸ› ï¸ Technologies utilisÃ©es
- **Python**  
- **NLTK, Pandas, Numpy, Scikit-learn**  
- **Keras (Tensorflow backend)**  
- **Matplotlib, Seaborn**  
- **GloVe embeddings**

## âœ… Conclusion
Le projet dÃ©montre que les rÃ©seaux de neurones rÃ©currents (**LSTM**) surpassent les modÃ¨les simples (MLP) et convolutionnels (CNN) pour la tÃ¢che de classification de dÃ©finitions, grÃ¢ce Ã  leur capacitÃ© Ã  capturer les dÃ©pendances sÃ©quentielles du langage.  
